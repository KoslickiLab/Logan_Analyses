#!/usr/bin/env python3
"""
Functional Hash-Diversity Correlation Analysis
================================================
Tests the hypothesis that distinct k-mer hashes per basepair correlates with functional diversity
(KEGG KO richness and abundance-aware metrics) in WGS metagenomic samples.

This script analyzes FracMinHash sketches (k=33 amino acid / scale=1000) generated by fmh-funprofiler.
The hash counts represent approximately 1/1000 of the 11-mers (amino acid) present in each sample.

This script:
1. Queries WGS metagenomic samples from metadata database
2. Extracts hash counts from functional_profile_data.gather_data
3. Extracts KO abundance data from functional_profile.profiles
4. Calculates multiple diversity metrics:
   - Observed Richness (number of KOs)
   - Shannon Index (H')
   - Simpson's Index (D) and Gini-Simpson (1-D)
   - Hill Number of Order 2 (effective number of species)
   - Berger-Parker Index (dominance)
   - Pielou's Evenness (J')
5. Calculates normalized metrics (per megabase)
6. Performs correlation analysis for each diversity metric
7. Generates publication-quality visualizations

Usage:
    python functional_hash_diversity_correlation.py --output-dir results --n-jobs 128
"""

from __future__ import annotations

import argparse
import sys
import time
from pathlib import Path
from dataclasses import dataclass
from typing import Dict, List, Tuple, Optional
import warnings

import duckdb
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import pearsonr, spearmanr, kendalltau
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
from concurrent.futures import ProcessPoolExecutor, as_completed
from tqdm import tqdm

# Import optional correlation libraries
try:
    import dcor
    HAS_DCOR = True
except ImportError:
    HAS_DCOR = False
    print("Note: dcor not installed - distance correlation will be skipped")

try:
    from minepy import MINE
    HAS_MINE = True
except ImportError:
    HAS_MINE = False
    print("Note: minepy not installed - MIC will be skipped")

warnings.filterwarnings('ignore', category=FutureWarning)
warnings.filterwarnings('ignore', category=UserWarning)

# Set publication-quality style
sns.set_style("whitegrid")
sns.set_context("paper", font_scale=1.5)
plt.rcParams['figure.dpi'] = 300
plt.rcParams['savefig.dpi'] = 300
plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans']

# Database paths
YACHT_DB = "/scratch/shared_data_new/Logan_yacht_data/processed_data/database_all.db"
METADATA_DB = "/scratch/shared_data_new/Logan_yacht_data/metadata/aws_sra_metadata/metadata_geo_joined_5M.duckdb"

# Diversity metrics to calculate
DIVERSITY_METRICS = [
    'observed_richness',
    'shannon_index',
    'simpson_index',
    'gini_simpson',
    'hill_2',
    'berger_parker',
    'pielou_evenness'
]


@dataclass
class Config:
    """Configuration for the analysis."""
    output_dir: Path
    n_samples: Optional[int] = None  # None = all samples
    n_jobs: int = 64  # Number of parallel workers
    random_seed: int = 42
    min_mbases: float = 100.0
    normalization_factor: float = 1_000_000.0  # Per million bases
    figure_size: Tuple[float, float] = (10, 8)
    dpi: int = 300
    
    def __post_init__(self):
        self.output_dir = Path(self.output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        (self.output_dir / "plots").mkdir(exist_ok=True)
        (self.output_dir / "data").mkdir(exist_ok=True)
        (self.output_dir / "reports").mkdir(exist_ok=True)


def calculate_diversity_metrics(abundances: np.ndarray) -> Dict[str, float]:
    """
    Calculate multiple diversity metrics from abundance data.
    
    Args:
        abundances: Array of abundances (counts or proportions)
        
    Returns:
        Dictionary of diversity metrics
    """
    # Filter out zeros and convert to numpy
    abundances = np.array(abundances)
    abundances = abundances[abundances > 0]
    
    if len(abundances) == 0:
        return {metric: np.nan for metric in DIVERSITY_METRICS}
    
    # Calculate proportional abundances
    total = abundances.sum()
    if total == 0:
        return {metric: np.nan for metric in DIVERSITY_METRICS}
    
    p = abundances / total
    
    # Observed Richness (S) - number of species/KOs
    S = len(abundances)
    
    # Shannon Index (H') = -Σ(p_i * ln(p_i))
    # Only use non-zero proportions to avoid log(0)
    shannon = -np.sum(p * np.log(p))
    
    # Simpson's Index (D) = Σ(p_i²)
    simpson_d = np.sum(p ** 2)
    
    # Gini-Simpson Index = 1 - D
    gini_simpson = 1 - simpson_d
    
    # Hill Number of Order 2 = 1/D (effective number of species)
    # Also called Simpson's reciprocal or inverse Simpson
    hill_2 = 1 / simpson_d if simpson_d > 0 else np.nan
    
    # Berger-Parker Index = n_max / N (dominance by most abundant)
    berger_parker = np.max(p)
    
    # Pielou's Evenness (J') = H' / ln(S)
    pielou = shannon / np.log(S) if S > 1 else np.nan
    
    return {
        'observed_richness': S,
        'shannon_index': shannon,
        'simpson_index': simpson_d,
        'gini_simpson': gini_simpson,
        'hill_2': hill_2,
        'berger_parker': berger_parker,
        'pielou_evenness': pielou
    }


def get_wgs_samples(config: Config) -> pd.DataFrame:
    """
    Query metadata database to get WGS metagenomic sample accessions.
    
    Returns:
        DataFrame with columns: acc, mbases
    """
    print("\n" + "="*70)
    print("STEP 1: Querying WGS metagenomic samples")
    print("="*70)

    query = f"""
    SELECT 
        acc,
        mbases
    FROM metadata_geo_joined 
    WHERE assay_type = 'WGS' 
        AND libraryselection = 'RANDOM' 
        AND mbases > {config.min_mbases}
    ORDER BY acc
    """
    
    print(f"Connecting to {METADATA_DB}...")
    conn = duckdb.connect(METADATA_DB, read_only=True, config={'threads': 1})
    
    try:
        print("Executing query...")
        df = conn.execute(query).fetchdf()
        print(f"Found {len(df):,} WGS metagenomic samples")
        
        if config.n_samples and len(df) > config.n_samples:
            print(f"Randomly sampling {config.n_samples:,} samples (seed={config.random_seed})")
            df = df.sample(n=config.n_samples, random_state=config.random_seed)
            df = df.sort_values('acc').reset_index(drop=True)
        
        print(f"\nSample statistics:")
        print(f"  Mbases range: {df['mbases'].min():.1f} - {df['mbases'].max():.1f}")
        print(f"  Mbases mean: {df['mbases'].mean():.1f}")
        print(f"  Mbases median: {df['mbases'].median():.1f}")
        
        # Save sample list
        sample_file = config.output_dir / "data" / "selected_samples.csv"
        df.to_csv(sample_file, index=False)
        print(f"\nSaved sample list to: {sample_file}")
        
        return df
        
    finally:
        conn.close()


def process_sample_batch(sample_ids: List[str]) -> List[Dict]:
    """
    Process a batch of samples to extract hash counts and functional diversity metrics.
    
    This function is designed to be run in parallel.
    
    Returns:
        List of dicts with sample_id, num_hashes, and all diversity metrics
    """
    conn = duckdb.connect(YACHT_DB, read_only=True, config={'threads': 1})
    results = []
    
    try:
        for sample_id in sample_ids:
            try:
                # Query hash count from functional_profile_data.gather_data
                hash_query = f"""
                SELECT query_n_hashes 
                FROM functional_profile_data.gather_data 
                WHERE sample_id = '{sample_id}' 
                LIMIT 1
                """
                
                hash_result = conn.execute(hash_query).fetchdf()
                
                if hash_result.empty:
                    continue
                
                num_hashes = hash_result['query_n_hashes'].iloc[0]
                
                # Query KO abundances from functional_profile.profiles
                ko_query = f"""
                SELECT ko_id, abundance
                FROM functional_profile.profiles 
                WHERE sample_id = '{sample_id}'
                """
                
                ko_df = conn.execute(ko_query).fetchdf()
                
                if ko_df.empty:
                    continue
                
                # Calculate diversity metrics
                abundances = ko_df['abundance'].values
                diversity_metrics = calculate_diversity_metrics(abundances)
                
                # Build result dict
                result = {
                    'sample_id': sample_id,
                    'num_hashes': num_hashes,
                    'num_kos': len(ko_df),  # Raw count of KOs for reference
                }
                result.update(diversity_metrics)
                results.append(result)
                
            except Exception as e:
                print(f"Warning: Error processing {sample_id}: {e}", file=sys.stderr)
                continue
                
    finally:
        conn.close()
    
    return results


def extract_hash_and_diversity_data(samples_df: pd.DataFrame, config: Config) -> pd.DataFrame:
    """
    Extract hash counts and functional diversity metrics for all samples using parallel processing.
    
    Args:
        samples_df: DataFrame with sample accessions and mbases
        config: Configuration object
        
    Returns:
        DataFrame with columns: sample_id, num_hashes, diversity metrics, mbases
    """
    print("\n" + "="*70)
    print("STEP 2: Extracting hash counts and functional diversity metrics")
    print("="*70)
    print(f"Using {config.n_jobs} parallel workers")
    
    # Split samples into batches for parallel processing
    sample_ids = samples_df['acc'].tolist()
    batch_size = max(1, len(sample_ids) // (config.n_jobs * 4))
    batches = [sample_ids[i:i+batch_size] for i in range(0, len(sample_ids), batch_size)]
    
    print(f"Processing {len(sample_ids):,} samples in {len(batches)} batches")
    print(f"Batch size: ~{batch_size} samples")
    
    # Process batches in parallel
    all_results = []
    start_time = time.time()
    
    with ProcessPoolExecutor(max_workers=config.n_jobs) as executor:
        futures = {
            executor.submit(process_sample_batch, batch): i 
            for i, batch in enumerate(batches)
        }
        
        with tqdm(total=len(batches), desc="Processing batches") as pbar:
            for future in as_completed(futures):
                try:
                    batch_results = future.result()
                    all_results.extend(batch_results)
                except Exception as e:
                    print(f"\nError in batch: {e}", file=sys.stderr)
                pbar.update(1)
    
    elapsed = time.time() - start_time
    print(f"\nProcessing complete in {elapsed:.1f}s ({len(sample_ids)/elapsed:.1f} samples/s)")
    
    # Convert to DataFrame
    results_df = pd.DataFrame(all_results)
    
    if results_df.empty:
        print("ERROR: No data extracted! Check that samples exist in functional profile database.", 
              file=sys.stderr)
        sys.exit(1)
    
    print(f"\nSuccessfully extracted data for {len(results_df):,} samples")
    print(f"Samples with no data: {len(sample_ids) - len(results_df):,}")
    
    # Merge with mbases from original samples
    results_df = results_df.merge(
        samples_df[['acc', 'mbases']], 
        left_on='sample_id', 
        right_on='acc', 
        how='left'
    ).drop('acc', axis=1)
    
    # Calculate normalized metrics (per megabase)
    results_df['hashes_per_mb'] = results_df['num_hashes'] / results_df['mbases']
    
    # Normalize diversity metrics per megabase
    for metric in DIVERSITY_METRICS:
        if metric in results_df.columns:
            results_df[f'{metric}_per_mb'] = results_df[metric] / results_df['mbases']
    
    print(f"\nData summary:")
    print(f"  Hashes range: {results_df['num_hashes'].min():,.0f} - {results_df['num_hashes'].max():,.0f}")
    print(f"  Hashes per Mb range: {results_df['hashes_per_mb'].min():.2f} - {results_df['hashes_per_mb'].max():.2f}")
    print(f"  Observed richness (KOs) range: {results_df['observed_richness'].min():.0f} - {results_df['observed_richness'].max():.0f}")
    print(f"  Shannon index range: {results_df['shannon_index'].min():.2f} - {results_df['shannon_index'].max():.2f}")
    print(f"  Hill 2 range: {results_df['hill_2'].min():.2f} - {results_df['hill_2'].max():.2f}")
    
    # Save raw data
    data_file = config.output_dir / "data" / "functional_hash_diversity_data.csv"
    results_df.to_csv(data_file, index=False)
    print(f"\nSaved raw data to: {data_file}")
    
    # Save parquet file with key columns for downstream analysis
    parquet_cols = [
        'sample_id', 'num_hashes', 'hashes_per_mb', 'mbases',
        'observed_richness', 'shannon_index', 'simpson_index', 'gini_simpson',
        'hill_2', 'berger_parker', 'pielou_evenness',
        'observed_richness_per_mb', 'shannon_index_per_mb', 'simpson_index_per_mb',
        'gini_simpson_per_mb', 'hill_2_per_mb', 'berger_parker_per_mb', 'pielou_evenness_per_mb'
    ]
    
    # Only include columns that exist
    parquet_cols = [c for c in parquet_cols if c in results_df.columns]
    
    # Create dataframe with renamed accession column for consistency
    parquet_df = results_df[parquet_cols].copy()
    parquet_df = parquet_df.rename(columns={'sample_id': 'accession', 'num_hashes': 'total_distinct_hashes'})
    
    # Add alpha_diversity and diversity_per_mb for compatibility with downstream scripts
    parquet_df['alpha_diversity'] = parquet_df['observed_richness']
    parquet_df['diversity_per_mb'] = parquet_df['observed_richness_per_mb']
    
    # Save as parquet
    parquet_file = config.output_dir / "data" / "functional_hash_diversity_data.parquet"
    parquet_df.to_parquet(parquet_file, index=False)
    print(f"Saved parquet file to: {parquet_file}")
    print(f"  Columns: {parquet_df.columns.tolist()}")
    
    return results_df


def perform_correlation_analysis(df: pd.DataFrame, config: Config) -> Dict:
    """
    Perform correlation analysis between hashes and all diversity metrics.
    
    Args:
        df: DataFrame with hash and diversity data
        config: Configuration object
        
    Returns:
        Dictionary of analysis results for each metric
    """
    print("\n" + "="*70)
    print("STEP 3: Correlation analysis")
    print("="*70)
    
    all_results = {}
    
    # List of diversity metrics to correlate with hashes_per_mb
    metrics_to_analyze = [
        ('observed_richness_per_mb', 'Observed Richness per Mb'),
        ('shannon_index', 'Shannon Index (raw)'),
        ('simpson_index', 'Simpson Index (raw)'),
        ('gini_simpson', 'Gini-Simpson Index (raw)'),
        ('hill_2', 'Hill Number Order 2 (raw)'),
        ('berger_parker', 'Berger-Parker Index (raw)'),
        ('pielou_evenness', 'Pielou Evenness (raw)'),
    ]
    
    for metric_col, metric_name in metrics_to_analyze:
        if metric_col not in df.columns:
            continue
            
        # Remove rows with missing data
        df_clean = df.dropna(subset=['hashes_per_mb', metric_col])
        n_samples = len(df_clean)
        
        if n_samples < 10:
            print(f"\nSkipping {metric_name}: insufficient data (n={n_samples})")
            continue
        
        print(f"\nAnalyzing: {metric_name}")
        print(f"  Samples with complete data: {n_samples:,}")
        
        x = df_clean['hashes_per_mb'].values
        y = df_clean[metric_col].values
        
        # Calculate correlations
        pearson_r, pearson_p = pearsonr(x, y)
        spearman_r, spearman_p = spearmanr(x, y)
        kendall_tau, kendall_p = kendalltau(x, y)
        
        # Distance correlation
        if HAS_DCOR:
            try:
                distance_corr = dcor.distance_correlation(x, y)
            except:
                distance_corr = np.nan
        else:
            distance_corr = np.nan
        
        # MIC
        if HAS_MINE and n_samples >= 50:
            try:
                mine = MINE(alpha=0.6, c=15)
                mine.compute_score(x, y)
                mic_score = mine.mic()
            except:
                mic_score = np.nan
        else:
            mic_score = np.nan
        
        # Linear regression
        X = x.reshape(-1, 1)
        model = LinearRegression()
        model.fit(X, y)
        y_pred = model.predict(X)
        r2 = r2_score(y, y_pred)
        slope = model.coef_[0]
        intercept = model.intercept_
        
        results = {
            'metric_name': metric_name,
            'metric_col': metric_col,
            'n_samples': n_samples,
            'pearson_r': pearson_r,
            'pearson_p': pearson_p,
            'spearman_r': spearman_r,
            'spearman_p': spearman_p,
            'kendall_tau': kendall_tau,
            'kendall_p': kendall_p,
            'distance_corr': distance_corr,
            'mic': mic_score,
            'r2': r2,
            'slope': slope,
            'intercept': intercept,
        }
        
        all_results[metric_col] = results
        
        print(f"  Pearson r:  {pearson_r:.4f} (p={pearson_p:.2e})")
        print(f"  Spearman ρ: {spearman_r:.4f} (p={spearman_p:.2e})")
        print(f"  R²:         {r2:.4f}")
        if not np.isnan(distance_corr):
            print(f"  Distance corr: {distance_corr:.4f}")
    
    return all_results


def create_visualizations(df: pd.DataFrame, results: Dict, config: Config):
    """
    Create publication-quality visualizations for all diversity metrics.
    """
    print("\n" + "="*70)
    print("STEP 4: Creating visualizations")
    print("="*70)
    
    for metric_col, metric_results in results.items():
        metric_name = metric_results['metric_name']
        print(f"\nCreating plots for: {metric_name}")
        
        df_clean = df.dropna(subset=['hashes_per_mb', metric_col])
        
        if len(df_clean) < 10:
            continue
        
        # Main scatter plot with regression line
        fig, ax = plt.subplots(figsize=config.figure_size)
        
        ax.scatter(
            df_clean['hashes_per_mb'], 
            df_clean[metric_col],
            alpha=0.3,
            s=20,
            c='steelblue',
            edgecolors='none',
            rasterized=True
        )
        
        # Add regression line
        X = df_clean['hashes_per_mb'].values
        y_pred = metric_results['slope'] * X + metric_results['intercept']
        sort_idx = np.argsort(X)
        ax.plot(X[sort_idx], y_pred[sort_idx], 'r-', linewidth=2, label='Linear fit', zorder=10)
        
        # Labels and title
        ax.set_xlabel('Functional k-mer hash density per megabase\n(11-mer AA FracMinHash, scale=1000)', 
                      fontsize=14, fontweight='bold')
        ax.set_ylabel(metric_name, fontsize=14, fontweight='bold')
        ax.set_title(f'Correlation: Hash Density vs {metric_name}\nin WGS Metagenomic Samples',
                     fontsize=16, fontweight='bold', pad=20)
        
        # Stats box
        stats_text = f'n = {metric_results["n_samples"]:,}\n\n'
        stats_text += 'Linear:\n'
        stats_text += f'  Pearson r = {metric_results["pearson_r"]:.4f}\n'
        stats_text += f'  R² = {metric_results["r2"]:.4f}\n'
        stats_text += f'  p = {metric_results["pearson_p"]:.2e}\n\n'
        stats_text += 'Monotonic:\n'
        stats_text += f'  Spearman ρ = {metric_results["spearman_r"]:.4f}\n'
        stats_text += f'  Kendall τ = {metric_results["kendall_tau"]:.4f}\n\n'
        stats_text += 'Non-linear:\n'
        if not np.isnan(metric_results.get('distance_corr', np.nan)):
            stats_text += f'  Distance corr = {metric_results["distance_corr"]:.4f}\n'
        if not np.isnan(metric_results.get('mic', np.nan)):
            stats_text += f'  MIC = {metric_results["mic"]:.4f}'
        
        ax.text(
            0.05, 0.95, stats_text,
            transform=ax.transAxes,
            fontsize=11,
            verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),
            family='monospace'
        )
        
        ax.legend(loc='lower right', fontsize=12)
        ax.grid(True, alpha=0.3)
        plt.tight_layout()
        
        # Create safe filename
        safe_name = metric_col.replace('/', '_').replace(' ', '_')
        plot_file = config.output_dir / "plots" / f"hash_vs_{safe_name}_correlation.png"
        plt.savefig(plot_file, dpi=config.dpi, bbox_inches='tight')
        plt.close()
        print(f"  Saved: {plot_file.name}")
    
    # Create summary multi-panel figure
    create_summary_figure(df, results, config)
    
    # Create hexbin for main metric (observed richness)
    create_hexbin_plot(df, config)
    
    # Create distribution plots
    create_distribution_plots(df, config)


def create_summary_figure(df: pd.DataFrame, results: Dict, config: Config):
    """Create a multi-panel summary figure showing all metrics."""
    
    n_metrics = len(results)
    if n_metrics == 0:
        return
    
    n_cols = min(3, n_metrics)
    n_rows = int(np.ceil(n_metrics / n_cols))
    
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))
    if n_metrics == 1:
        axes = [axes]
    else:
        axes = axes.flatten()
    
    for idx, (metric_col, metric_results) in enumerate(results.items()):
        ax = axes[idx]
        df_clean = df.dropna(subset=['hashes_per_mb', metric_col])
        
        if len(df_clean) < 10:
            ax.text(0.5, 0.5, 'Insufficient data', ha='center', va='center', transform=ax.transAxes)
            continue
        
        ax.scatter(
            df_clean['hashes_per_mb'],
            df_clean[metric_col],
            alpha=0.3, s=10, c='steelblue', edgecolors='none', rasterized=True
        )
        
        # Regression line
        X = df_clean['hashes_per_mb'].values
        y_pred = metric_results['slope'] * X + metric_results['intercept']
        sort_idx = np.argsort(X)
        ax.plot(X[sort_idx], y_pred[sort_idx], 'r-', linewidth=2, alpha=0.8)
        
        # Stats annotation
        stats_text = f"ρ={metric_results['spearman_r']:.3f}\nr={metric_results['pearson_r']:.3f}\nR²={metric_results['r2']:.3f}"
        ax.text(0.05, 0.95, stats_text, transform=ax.transAxes, fontsize=9,
                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),
                family='monospace')
        
        ax.set_xlabel('Hashes per Mb', fontsize=10)
        ax.set_ylabel(metric_results['metric_name'].replace(' per Mb', '').replace(' (raw)', ''), fontsize=10)
        ax.set_title(metric_results['metric_name'].replace(' per Mb', '').replace(' (raw)', ''), 
                     fontsize=11, fontweight='bold')
        ax.grid(True, alpha=0.3)
    
    # Hide unused subplots
    for idx in range(len(results), len(axes)):
        axes[idx].set_visible(False)
    
    fig.suptitle('Functional Hash-Diversity Correlations: All Metrics', 
                 fontsize=14, fontweight='bold', y=0.995)
    
    plt.tight_layout()
    plt.savefig(config.output_dir / "plots" / "summary_all_metrics.png", 
                dpi=config.dpi, bbox_inches='tight')
    plt.close()
    print("Saved summary figure: summary_all_metrics.png")


def create_hexbin_plot(df: pd.DataFrame, config: Config):
    """Create hexbin plot for observed richness."""
    df_clean = df.dropna(subset=['hashes_per_mb', 'observed_richness_per_mb'])
    
    if len(df_clean) < 10:
        return
    
    fig, ax = plt.subplots(figsize=config.figure_size)
    hexbin = ax.hexbin(
        df_clean['hashes_per_mb'],
        df_clean['observed_richness_per_mb'],
        gridsize=50,
        cmap='YlOrRd',
        mincnt=1,
        bins='log'
    )
    ax.set_xlabel('Functional k-mer hash density per megabase\n(11-mer AA FracMinHash, scale=1000)', 
                  fontsize=14, fontweight='bold')
    ax.set_ylabel('Functional Richness (KOs) per megabase', fontsize=14, fontweight='bold')
    ax.set_title('Functional Hash Density vs KO Richness (Hexbin Density)', 
                 fontsize=16, fontweight='bold')
    plt.colorbar(hexbin, ax=ax, label='log10(count)')
    plt.tight_layout()
    plt.savefig(config.output_dir / "plots" / "hash_diversity_hexbin.png", 
                dpi=config.dpi, bbox_inches='tight')
    plt.close()
    print("Saved hexbin plot")


def create_distribution_plots(df: pd.DataFrame, config: Config):
    """Create distribution plots for key metrics."""
    fig, axes = plt.subplots(2, 3, figsize=(16, 10))
    
    # Hashes per Mb
    if 'hashes_per_mb' in df.columns:
        ax = axes[0, 0]
        ax.hist(df['hashes_per_mb'].dropna(), bins=50, edgecolor='black', alpha=0.7)
        ax.set_xlabel('Functional k-mer hash density per Mb\n(11-mer AA, scale=1000)')
        ax.set_ylabel('Frequency')
        ax.set_title('Distribution of Hash Density')
        ax.axvline(df['hashes_per_mb'].median(), color='red', linestyle='--', 
                   label=f'Median: {df["hashes_per_mb"].median():.2f}')
        ax.legend()
    
    # Observed Richness per Mb
    if 'observed_richness_per_mb' in df.columns:
        ax = axes[0, 1]
        ax.hist(df['observed_richness_per_mb'].dropna(), bins=50, edgecolor='black', alpha=0.7)
        ax.set_xlabel('KO Richness per Mb')
        ax.set_ylabel('Frequency')
        ax.set_title('Distribution of Functional Richness per Mb')
        ax.axvline(df['observed_richness_per_mb'].median(), color='red', linestyle='--',
                   label=f'Median: {df["observed_richness_per_mb"].median():.4f}')
        ax.legend()
    
    # Shannon Index
    if 'shannon_index' in df.columns:
        ax = axes[0, 2]
        ax.hist(df['shannon_index'].dropna(), bins=50, edgecolor='black', alpha=0.7)
        ax.set_xlabel('Shannon Index')
        ax.set_ylabel('Frequency')
        ax.set_title('Distribution of Shannon Index')
        ax.axvline(df['shannon_index'].median(), color='red', linestyle='--',
                   label=f'Median: {df["shannon_index"].median():.2f}')
        ax.legend()
    
    # Hill Number Order 2
    if 'hill_2' in df.columns:
        ax = axes[1, 0]
        ax.hist(df['hill_2'].dropna(), bins=50, edgecolor='black', alpha=0.7)
        ax.set_xlabel('Hill Number (Order 2)')
        ax.set_ylabel('Frequency')
        ax.set_title('Distribution of Hill Number (Order 2)')
        ax.set_yscale('log')
    
    # Berger-Parker Index
    if 'berger_parker' in df.columns:
        ax = axes[1, 1]
        ax.hist(df['berger_parker'].dropna(), bins=50, edgecolor='black', alpha=0.7)
        ax.set_xlabel('Berger-Parker Index (Dominance)')
        ax.set_ylabel('Frequency')
        ax.set_title('Distribution of Berger-Parker Index')
    
    # Pielou Evenness
    if 'pielou_evenness' in df.columns:
        ax = axes[1, 2]
        ax.hist(df['pielou_evenness'].dropna(), bins=50, edgecolor='black', alpha=0.7)
        ax.set_xlabel("Pielou's Evenness")
        ax.set_ylabel('Frequency')
        ax.set_title("Distribution of Pielou's Evenness")
    
    plt.tight_layout()
    plt.savefig(config.output_dir / "plots" / "distributions.png", 
                dpi=config.dpi, bbox_inches='tight')
    plt.close()
    print("Saved distribution plots")


def generate_report(df: pd.DataFrame, results: Dict, config: Config):
    """Generate a comprehensive text report of the analysis."""
    print("\n" + "="*70)
    print("STEP 5: Generating report")
    print("="*70)
    
    report_file = config.output_dir / "reports" / "analysis_report.txt"
    
    with open(report_file, 'w') as f:
        f.write("="*70 + "\n")
        f.write("FUNCTIONAL HASH-DIVERSITY CORRELATION ANALYSIS REPORT\n")
        f.write("="*70 + "\n\n")
        
        f.write(f"Analysis Date: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Minimum Mbases: {config.min_mbases}\n")
        f.write(f"FracMinHash Parameters: k=11 (amino acid), scale=1000\n\n")
        
        f.write("-"*70 + "\n")
        f.write("DATA SUMMARY\n")
        f.write("-"*70 + "\n")
        f.write(f"Total samples analyzed: {len(df):,}\n\n")
        
        f.write("Raw Metrics:\n")
        f.write(f"  Distinct hashes:\n")
        f.write(f"    Range: {df['num_hashes'].min():,.0f} - {df['num_hashes'].max():,.0f}\n")
        f.write(f"    Mean: {df['num_hashes'].mean():,.0f}\n")
        f.write(f"    Median: {df['num_hashes'].median():,.0f}\n\n")
        
        f.write(f"  Observed KO Richness:\n")
        f.write(f"    Range: {df['observed_richness'].min():.0f} - {df['observed_richness'].max():.0f}\n")
        f.write(f"    Mean: {df['observed_richness'].mean():.2f}\n")
        f.write(f"    Median: {df['observed_richness'].median():.0f}\n\n")
        
        f.write(f"  Shannon Index:\n")
        f.write(f"    Range: {df['shannon_index'].min():.2f} - {df['shannon_index'].max():.2f}\n")
        f.write(f"    Mean: {df['shannon_index'].mean():.2f}\n")
        f.write(f"    Median: {df['shannon_index'].median():.2f}\n\n")
        
        f.write(f"  Hill Number (Order 2):\n")
        f.write(f"    Range: {df['hill_2'].min():.2f} - {df['hill_2'].max():.2f}\n")
        f.write(f"    Mean: {df['hill_2'].mean():.2f}\n")
        f.write(f"    Median: {df['hill_2'].median():.2f}\n\n")
        
        f.write(f"  Sequencing depth (Mbases):\n")
        f.write(f"    Range: {df['mbases'].min():.1f} - {df['mbases'].max():.1f} Mb\n")
        f.write(f"    Mean: {df['mbases'].mean():.1f} Mb\n")
        f.write(f"    Median: {df['mbases'].median():.1f} Mb\n\n")
        
        f.write("-"*70 + "\n")
        f.write("CORRELATION ANALYSIS RESULTS\n")
        f.write("-"*70 + "\n\n")
        
        for metric_col, metric_results in results.items():
            f.write(f"Metric: {metric_results['metric_name']}\n")
            f.write("-"*50 + "\n")
            f.write(f"  Samples: {metric_results['n_samples']:,}\n")
            f.write(f"  Linear:\n")
            f.write(f"    Pearson r: {metric_results['pearson_r']:.6f} (p={metric_results['pearson_p']:.2e})\n")
            f.write(f"    R²: {metric_results['r2']:.6f}\n")
            f.write(f"    Regression: y = {metric_results['slope']:.8f}x + {metric_results['intercept']:.8f}\n")
            f.write(f"  Monotonic:\n")
            f.write(f"    Spearman ρ: {metric_results['spearman_r']:.6f} (p={metric_results['spearman_p']:.2e})\n")
            f.write(f"    Kendall τ: {metric_results['kendall_tau']:.6f} (p={metric_results['kendall_p']:.2e})\n")
            if not np.isnan(metric_results.get('distance_corr', np.nan)):
                f.write(f"  Non-linear:\n")
                f.write(f"    Distance correlation: {metric_results['distance_corr']:.6f}\n")
            if not np.isnan(metric_results.get('mic', np.nan)):
                f.write(f"    MIC: {metric_results['mic']:.6f}\n")
            f.write("\n")
        
        f.write("-"*70 + "\n")
        f.write("INTERPRETATION\n")
        f.write("-"*70 + "\n\n")
        
        # Summarize overall findings
        if 'observed_richness_per_mb' in results:
            r = results['observed_richness_per_mb']
            f.write(f"Primary finding (KO Richness):\n")
            f.write(f"  The relationship between hash density and functional richness\n")
            f.write(f"  shows Spearman ρ = {r['spearman_r']:.4f}, Pearson r = {r['pearson_r']:.4f}\n\n")
        
        f.write("Diversity metric comparisons:\n")
        for metric_col, metric_results in results.items():
            direction = "positive" if metric_results['spearman_r'] > 0 else "negative"
            strength = "strong" if abs(metric_results['spearman_r']) > 0.7 else "moderate" if abs(metric_results['spearman_r']) > 0.4 else "weak"
            f.write(f"  {metric_results['metric_name']}: {strength} {direction} (ρ={metric_results['spearman_r']:.3f})\n")
        
        f.write("\n")
        f.write("-"*70 + "\n")
        f.write("OUTPUT FILES\n")
        f.write("-"*70 + "\n")
        f.write(f"Data:\n")
        f.write(f"  {config.output_dir / 'data' / 'functional_hash_diversity_data.csv'}\n")
        f.write(f"  {config.output_dir / 'data' / 'functional_hash_diversity_data.parquet'}\n\n")
        f.write(f"Plots:\n")
        f.write(f"  {config.output_dir / 'plots' / 'summary_all_metrics.png'}\n")
        f.write(f"  {config.output_dir / 'plots' / 'hash_diversity_hexbin.png'}\n")
        f.write(f"  {config.output_dir / 'plots' / 'distributions.png'}\n")
        f.write(f"  (Individual metric plots in plots/ directory)\n\n")
        f.write(f"Reports:\n")
        f.write(f"  {config.output_dir / 'reports' / 'analysis_report.txt'}\n")
        f.write(f"  {config.output_dir / 'reports' / 'statistics_summary.csv'}\n\n")
        
        f.write("="*70 + "\n")
        f.write("END OF REPORT\n")
        f.write("="*70 + "\n")
    
    print(f"Saved report to: {report_file}")
    
    # Save statistics as CSV
    stats_rows = []
    for metric_col, metric_results in results.items():
        stats_rows.append(metric_results)
    
    stats_df = pd.DataFrame(stats_rows)
    stats_file = config.output_dir / "reports" / "statistics_summary.csv"
    stats_df.to_csv(stats_file, index=False)
    print(f"Saved statistics to: {stats_file}")


def main():
    """Main analysis pipeline."""
    parser = argparse.ArgumentParser(
        description="Test correlation between distinct hashes and functional diversity",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument(
        '--output-dir', '-o',
        type=str,
        required=True,
        help='Output directory for results'
    )
    parser.add_argument(
        '--n-samples', '-n',
        type=int,
        default=None,
        help='Number of samples to analyze (default: all available samples)'
    )
    parser.add_argument(
        '--n-jobs', '-j',
        type=int,
        default=64,
        help='Number of parallel workers'
    )
    parser.add_argument(
        '--min-mbases', '-m',
        type=float,
        default=100.0,
        help='Minimum megabases for sample inclusion'
    )
    parser.add_argument(
        '--random-seed',
        type=int,
        default=42,
        help='Random seed for reproducibility'
    )
    parser.add_argument(
        '--dpi',
        type=int,
        default=300,
        help='DPI for saved figures'
    )
    
    args = parser.parse_args()
    
    # Create configuration
    config = Config(
        output_dir=args.output_dir,
        n_samples=args.n_samples,
        n_jobs=args.n_jobs,
        min_mbases=args.min_mbases,
        random_seed=args.random_seed,
        dpi=args.dpi
    )
    
    print("\n" + "="*70)
    print("FUNCTIONAL HASH-DIVERSITY CORRELATION ANALYSIS")
    print("="*70)
    print(f"Configuration:")
    print(f"  Output directory: {config.output_dir}")
    print(f"  Number of samples: {'all' if config.n_samples is None else f'{config.n_samples:,}'}")
    print(f"  Parallel workers: {config.n_jobs}")
    print(f"  Minimum mbases: {config.min_mbases}")
    print(f"  Random seed: {config.random_seed}")
    print(f"  FracMinHash: k=11 (amino acid), scale=1000")
    print("="*70)
    
    start_time = time.time()
    
    # Step 1: Get WGS samples
    samples_df = get_wgs_samples(config)
    
    # Step 2: Extract hash and diversity data
    data_df = extract_hash_and_diversity_data(samples_df, config)
    
    # Step 3: Perform correlation analysis
    results = perform_correlation_analysis(data_df, config)
    
    # Step 4: Create visualizations
    create_visualizations(data_df, results, config)
    
    # Step 5: Generate report
    generate_report(data_df, results, config)
    
    elapsed = time.time() - start_time
    
    print("\n" + "="*70)
    print("ANALYSIS COMPLETE")
    print("="*70)
    print(f"Total time: {elapsed/60:.1f} minutes")
    
    if 'observed_richness_per_mb' in results:
        r = results['observed_richness_per_mb']
        print(f"\nKey findings (KO Richness):")
        print(f"  Spearman ρ = {r['spearman_r']:.4f} (p = {r['spearman_p']:.2e})")
        print(f"  Pearson r = {r['pearson_r']:.4f} (p = {r['pearson_p']:.2e})")
        print(f"  R² = {r['r2']:.4f}")
        print(f"  Samples analyzed: {r['n_samples']:,}")
    
    print(f"\nOutputs saved to: {config.output_dir}/")
    print("="*70 + "\n")


if __name__ == "__main__":
    main()
